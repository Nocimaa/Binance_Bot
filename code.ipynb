{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXLcSoxJk33eSiO+RLspVc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nocimaa/Binance_Bot/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oiTAtF6gJgf",
        "outputId": "e693ffd2-78cc-4ba5-f53a-4f4cb4214b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-18 10:03:09--  https://raw.githubusercontent.com/Nocimaa/Binance_Bot/refs/heads/main/btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28620838 (27M) [text/plain]\n",
            "Saving to: ‘btc_1h_adx_2017-08-17_to_2025-09-17(in).csv’\n",
            "\n",
            "btc_1h_adx_2017-08- 100%[===================>]  27.29M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-09-18 10:03:10 (240 MB/s) - ‘btc_1h_adx_2017-08-17_to_2025-09-17(in).csv’ saved [28620838/28620838]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://raw.githubusercontent.com/Nocimaa/Binance_Bot/refs/heads/main/btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Test"
      ],
      "metadata": {
        "id": "en6-eWhqgiaB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base = pd.read_csv(\"btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\")\n",
        "\n",
        "df = base[base[\"timestamp\"] < \"2025-09-01 00:00:00+02:00\"]\n",
        "predict_df = base[base[\"timestamp\"] >= \"2025-09-01 00:00:00+02:00\"]\n",
        "\n",
        "def max_log_return(close, high, low):\n",
        "    log_high = np.log(high / close)\n",
        "    log_low = np.log(low / close)\n",
        "    return log_high if abs(log_high) > abs(log_low) else log_low\n",
        "\n",
        "def preprocessing(df, index_label=True):\n",
        "  if index_label:\n",
        "    # df[\"label\"] = np.log()\n",
        "    df[\"label\"] = [\n",
        "      max_log_return(c, h, l)\n",
        "      for c, h, l in zip(df[\"close\"], df[\"high\"].shift(-1), df[\"low\"].shift(-1))\n",
        "    ]\n",
        "  df = df.drop(\"timestamp\", axis=1)\n",
        "  # df = df.drop(\"close\", axis=1)\n",
        "\n",
        "\n",
        "  features = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"ATR14\",\"MACD\"]\n",
        "  window = 3\n",
        "  for f in features:\n",
        "      for w in range(1, window+1):\n",
        "          df[f\"{f}_lag{w}\"] = df[f].shift(w)\n",
        "\n",
        "\n",
        "  df.dropna(inplace=True)\n",
        "  return df\n",
        "\n",
        "df = preprocessing(df)\n",
        "predict_df = preprocessing(predict_df, index_label=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmOryAAwgtC7",
        "outputId": "29aa80b5-93e8-4632-c390-72cd2f0624bc"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-516855664.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[\"label\"] = [\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "df[\"label\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "y1U0Miu7gw_b",
        "outputId": "36e1650d-0aac-4c49-c858-799cdc10fbb3"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3       -0.021783\n",
              "4       -0.005761\n",
              "5       -0.016528\n",
              "6        0.017963\n",
              "7       -0.017351\n",
              "           ...   \n",
              "70249    0.000652\n",
              "70250    0.002233\n",
              "70251   -0.002113\n",
              "70252    0.001724\n",
              "70253   -0.001475\n",
              "Name: label, Length: 70251, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.021783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.005761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.016528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.017963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.017351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70249</th>\n",
              "      <td>0.000652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70250</th>\n",
              "      <td>0.002233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70251</th>\n",
              "      <td>-0.002113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70252</th>\n",
              "      <td>0.001724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70253</th>\n",
              "      <td>-0.001475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>70251 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[\"label\"]\n",
        "X = df.drop(\"label\", axis=1)"
      ],
      "metadata": {
        "id": "P16J24ChiDe9"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "k = 30\n",
        "selector = SelectKBest(score_func=f_regression, k=k)\n",
        "X_new = selector.fit_transform(X, y)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_new = scaler.fit_transform(X_new)"
      ],
      "metadata": {
        "id": "6TOXhziajFuL"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zdUb3aTujKqj"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "def create_sequences(X, y, seq_len=50):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - seq_len):\n",
        "        Xs.append(X[i:i+seq_len])\n",
        "        ys.append(y[i+seq_len])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "\n",
        "y_scaler = StandardScaler()\n",
        "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
        "y_test_scaled  = y_scaler.transform(y_test.values.reshape(-1,1))\n",
        "\n",
        "seq_len = 5  # tu peux ajuster\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train, y_train_scaled, seq_len)\n",
        "X_test_seq, y_test_seq   = create_sequences(X_test,  y_test_scaled,  seq_len)\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).to(device)\n",
        "\n",
        "X_test_tensor  = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\n",
        "y_test_tensor  = torch.tensor(y_test_seq, dtype=torch.float32).to(device)"
      ],
      "metadata": {
        "id": "B9A7VhBZj5ty"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=256, num_layers=4, dropout=0.4):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # LSTM empilé\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_dim,\n",
        "            hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Normalisation + Fully Connected\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.fc1 = nn.Linear(hidden_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, seq_len, input_dim\n",
        "\n",
        "        out, _ = self.lstm(x)  # out: (batch, seq_len, hidden_dim)\n",
        "        out = out[:, -1, :]    # garder le dernier état\n",
        "        out = self.bn(out)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = self.dropout(out)\n",
        "        return self.fc2(out)\n",
        "\n",
        "\n",
        "model = LSTMNet(input_dim=k)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "aygb4S84j-de"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.SmoothL1Loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "zsVOmjhEkKJH"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    permutation = torch.randperm(X_train_tensor.size(0))\n",
        "    for i in range(0, X_train_tensor.size(0), batch_size):\n",
        "        indices = permutation[i:i+batch_size]\n",
        "        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Évaluation train\n",
        "    with torch.no_grad():\n",
        "        preds = model(X_train_tensor)\n",
        "        mse = criterion(preds, y_train_tensor).item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Train MSE={mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4vTCmLskcR7",
        "outputId": "4d76a5f1-f6cf-41b7-e3a9-6433283462aa"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train MSE=0.3321\n",
            "Epoch 2/100, Train MSE=0.3312\n",
            "Epoch 3/100, Train MSE=0.3307\n",
            "Epoch 4/100, Train MSE=0.3309\n",
            "Epoch 5/100, Train MSE=0.3307\n",
            "Epoch 6/100, Train MSE=0.3308\n",
            "Epoch 7/100, Train MSE=0.3308\n",
            "Epoch 8/100, Train MSE=0.3307\n",
            "Epoch 9/100, Train MSE=0.3307\n",
            "Epoch 10/100, Train MSE=0.3310\n",
            "Epoch 11/100, Train MSE=0.3307\n",
            "Epoch 12/100, Train MSE=0.3306\n",
            "Epoch 13/100, Train MSE=0.3306\n",
            "Epoch 14/100, Train MSE=0.3306\n",
            "Epoch 15/100, Train MSE=0.3305\n",
            "Epoch 16/100, Train MSE=0.3305\n",
            "Epoch 17/100, Train MSE=0.3305\n",
            "Epoch 18/100, Train MSE=0.3304\n",
            "Epoch 19/100, Train MSE=0.3303\n",
            "Epoch 20/100, Train MSE=0.3305\n",
            "Epoch 21/100, Train MSE=0.3303\n",
            "Epoch 22/100, Train MSE=0.3303\n",
            "Epoch 23/100, Train MSE=0.3305\n",
            "Epoch 24/100, Train MSE=0.3303\n",
            "Epoch 25/100, Train MSE=0.3304\n",
            "Epoch 26/100, Train MSE=0.3302\n",
            "Epoch 27/100, Train MSE=0.3297\n",
            "Epoch 28/100, Train MSE=0.3298\n",
            "Epoch 29/100, Train MSE=0.3293\n",
            "Epoch 30/100, Train MSE=0.3290\n",
            "Epoch 31/100, Train MSE=0.3287\n",
            "Epoch 32/100, Train MSE=0.3274\n",
            "Epoch 33/100, Train MSE=0.3265\n",
            "Epoch 34/100, Train MSE=0.3253\n",
            "Epoch 35/100, Train MSE=0.3230\n",
            "Epoch 36/100, Train MSE=0.3203\n",
            "Epoch 37/100, Train MSE=0.3173\n",
            "Epoch 38/100, Train MSE=0.3142\n",
            "Epoch 39/100, Train MSE=0.3076\n",
            "Epoch 40/100, Train MSE=0.3033\n",
            "Epoch 41/100, Train MSE=0.2988\n",
            "Epoch 42/100, Train MSE=0.2892\n",
            "Epoch 43/100, Train MSE=0.2826\n",
            "Epoch 44/100, Train MSE=0.2751\n",
            "Epoch 45/100, Train MSE=0.2645\n",
            "Epoch 46/100, Train MSE=0.2571\n",
            "Epoch 47/100, Train MSE=0.2483\n",
            "Epoch 48/100, Train MSE=0.2396\n",
            "Epoch 49/100, Train MSE=0.2299\n",
            "Epoch 50/100, Train MSE=0.2225\n",
            "Epoch 51/100, Train MSE=0.2169\n",
            "Epoch 52/100, Train MSE=0.2069\n",
            "Epoch 53/100, Train MSE=0.2006\n",
            "Epoch 54/100, Train MSE=0.1945\n",
            "Epoch 55/100, Train MSE=0.1889\n",
            "Epoch 56/100, Train MSE=0.1830\n",
            "Epoch 57/100, Train MSE=0.1773\n",
            "Epoch 58/100, Train MSE=0.1740\n",
            "Epoch 59/100, Train MSE=0.1685\n",
            "Epoch 60/100, Train MSE=0.1619\n",
            "Epoch 61/100, Train MSE=0.1589\n",
            "Epoch 62/100, Train MSE=0.1517\n",
            "Epoch 63/100, Train MSE=0.1480\n",
            "Epoch 64/100, Train MSE=0.1487\n",
            "Epoch 65/100, Train MSE=0.1414\n",
            "Epoch 66/100, Train MSE=0.1350\n",
            "Epoch 67/100, Train MSE=0.1365\n",
            "Epoch 68/100, Train MSE=0.1327\n",
            "Epoch 69/100, Train MSE=0.1290\n",
            "Epoch 70/100, Train MSE=0.1268\n",
            "Epoch 71/100, Train MSE=0.1244\n",
            "Epoch 72/100, Train MSE=0.1214\n",
            "Epoch 73/100, Train MSE=0.1202\n",
            "Epoch 74/100, Train MSE=0.1164\n",
            "Epoch 75/100, Train MSE=0.1139\n",
            "Epoch 76/100, Train MSE=0.1126\n",
            "Epoch 77/100, Train MSE=0.1120\n",
            "Epoch 78/100, Train MSE=0.1082\n",
            "Epoch 79/100, Train MSE=0.1066\n",
            "Epoch 80/100, Train MSE=0.1041\n",
            "Epoch 81/100, Train MSE=0.0998\n",
            "Epoch 82/100, Train MSE=0.1038\n",
            "Epoch 83/100, Train MSE=0.0982\n",
            "Epoch 84/100, Train MSE=0.0976\n",
            "Epoch 85/100, Train MSE=0.0972\n",
            "Epoch 86/100, Train MSE=0.0932\n",
            "Epoch 87/100, Train MSE=0.0944\n",
            "Epoch 88/100, Train MSE=0.0912\n",
            "Epoch 89/100, Train MSE=0.0892\n",
            "Epoch 90/100, Train MSE=0.0884\n",
            "Epoch 91/100, Train MSE=0.0866\n",
            "Epoch 92/100, Train MSE=0.0856\n",
            "Epoch 93/100, Train MSE=0.0849\n",
            "Epoch 94/100, Train MSE=0.0826\n",
            "Epoch 95/100, Train MSE=0.0864\n",
            "Epoch 96/100, Train MSE=0.0797\n",
            "Epoch 97/100, Train MSE=0.0820\n",
            "Epoch 98/100, Train MSE=0.0814\n",
            "Epoch 99/100, Train MSE=0.0790\n",
            "Epoch 100/100, Train MSE=0.0771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "with torch.no_grad():\n",
        "    # prédictions sur GPU\n",
        "    preds = model(X_test_tensor)\n",
        "\n",
        "    # ramener sur CPU avant conversion en numpy\n",
        "    preds_cpu = preds.cpu().numpy()\n",
        "    y_true_cpu = y_test_tensor.cpu().numpy()\n",
        "\n",
        "    # si tu as utilisé un scaler pour y\n",
        "    preds_orig = y_scaler.inverse_transform(preds_cpu)\n",
        "    y_true_orig = y_scaler.inverse_transform(y_true_cpu)\n",
        "\n",
        "    # calcul métriques\n",
        "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "    import numpy as np\n",
        "\n",
        "    mse_test = mean_squared_error(y_true_orig, preds_orig)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    mae_test = mean_absolute_error(y_true_orig, preds_orig)\n",
        "\n",
        "print(f\"\\nTest MSE (original scale) = {mse_test:.4f}\")\n",
        "print(f\"Test RMSE (original scale) = {rmse_test:.4f}\")\n",
        "print(f\"Test MAE (original scale)  = {mae_test:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVPjeLlBk8Ft",
        "outputId": "99ca7e40-db29-4a84-a6b7-c8ded8cdf159"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test MSE (original scale) = 0.0002\n",
            "Test RMSE (original scale) = 0.0145\n",
            "Test MAE (original scale)  = 0.0101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_row(seq_rows, model, selector, scaler_X, scaler_y, feature_columns, device='cpu'):\n",
        "    \"\"\"\n",
        "    Prédit le label à partir d'une séquence de nouvelles données (LSTM).\n",
        "\n",
        "    Args:\n",
        "        seq_rows (list[pd.Series] ou pd.DataFrame): séquence de lignes (longueur = seq_len)\n",
        "        model (torch.nn.Module): modèle PyTorch déjà entraîné\n",
        "        selector (sklearn transformer): SelectKBest ou autre\n",
        "        scaler_X (StandardScaler): scaler pour X\n",
        "        scaler_y (StandardScaler): scaler pour y\n",
        "        feature_columns (list): noms des colonnes/features utilisées\n",
        "        device (str): 'cpu' ou 'cuda'\n",
        "\n",
        "    Returns:\n",
        "        float: prédiction en échelle originale\n",
        "    \"\"\"\n",
        "    # 1️⃣ Construire DataFrame à partir de la séquence\n",
        "    if isinstance(seq_rows, list):\n",
        "        df_seq = pd.DataFrame(seq_rows, columns=feature_columns)\n",
        "    elif isinstance(seq_rows, pd.Series):\n",
        "        df_seq = pd.DataFrame([seq_rows], columns=feature_columns)\n",
        "    else:\n",
        "        df_seq = seq_rows.copy()\n",
        "\n",
        "    # 2️⃣ Supprimer colonne timestamp si présente\n",
        "    if \"timestamp\" in df_seq.columns:\n",
        "        df_seq = df_seq.drop(columns=[\"timestamp\"])\n",
        "\n",
        "    # 3️⃣ Appliquer la sélection de features\n",
        "    X_new = selector.transform(df_seq)\n",
        "\n",
        "    # 4️⃣ Normaliser\n",
        "    X_new_scaled = scaler_X.transform(X_new)\n",
        "\n",
        "    # 5️⃣ Convertir en tenseur avec bonne forme (batch=1, seq_len, input_dim)\n",
        "    X_tensor = torch.tensor(X_new_scaled, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    # 6️⃣ Prédiction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred_scaled = model(X_tensor)\n",
        "        pred = scaler_y.inverse_transform(pred_scaled.cpu().numpy())\n",
        "\n",
        "    return float(pred[0][0])\n",
        "\n",
        "\n",
        "seq_len = 5\n",
        "seq_input = predict_df.iloc[0:seq_len].drop(columns=[\"label\"])  # lignes 0 à 4\n",
        "variation = predict_new_row(seq_input, model, selector, scaler, y_scaler, X.columns, device)\n",
        "print(\"Prédiction:\", variation)"
      ],
      "metadata": {
        "id": "Zifd7Mo5q_nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0991fe8e-52e8-4548-c4cc-f446e2460ee9"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prédiction: 0.0038391316775232553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ODqHQRJTlY9w"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odshoFIBS5L7",
        "outputId": "82303899-415a-49cc-863d-e89bb2b0fe07"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['open', 'high', 'low', 'close', 'volume', 'ADX', '+DI', '-DI', 'ATR14',\n",
              "       'BB_width', 'BB_pctB', 'RSI14', 'StochK', 'StochD', 'MACD',\n",
              "       'MACD_signal', 'ROC', 'OBV', 'Vol_zscore', 'log_ret',\n",
              "       'close_open_ratio', 'high_low_spread', 'hour', 'dayofweek', 'label',\n",
              "       'open_lag1', 'open_lag2', 'open_lag3', 'high_lag1', 'high_lag2',\n",
              "       'high_lag3', 'low_lag1', 'low_lag2', 'low_lag3', 'close_lag1',\n",
              "       'close_lag2', 'close_lag3', 'volume_lag1', 'volume_lag2', 'volume_lag3',\n",
              "       'ATR14_lag1', 'ATR14_lag2', 'ATR14_lag3', 'MACD_lag1', 'MACD_lag2',\n",
              "       'MACD_lag3'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = 0\n",
        "wallet = 10\n",
        "lever = 1\n",
        "fee_rate = 0.0004  # frais Binance typique\n",
        "seq_len = 5\n",
        "safety_pct = 0.5 / 100  # % de sécurité relatif à la variation prédite\n",
        "\n",
        "for i in range(len(predict_df) - seq_len):\n",
        "    seq_input = predict_df.iloc[i:i+seq_len].drop(columns=[\"label\"])\n",
        "    variation = predict_new_row(seq_input, model, selector, scaler, y_scaler, X.columns, device)\n",
        "\n",
        "    if abs(variation) > 0.001:\n",
        "        t += 1\n",
        "        str_variation = \"baisse\" if variation < 0 else \"monte\"\n",
        "\n",
        "        price_open = float(predict_df.iloc[i + seq_len - 1]['open'])\n",
        "        price_next_close = float(predict_df.iloc[i + seq_len]['close'])\n",
        "        price_high = float(predict_df.iloc[i + seq_len]['high'])\n",
        "        price_low = float(predict_df.iloc[i + seq_len]['low'])\n",
        "\n",
        "        # Écart attendu selon la variation\n",
        "        expected_move = price_open * variation\n",
        "        security = abs(expected_move) * safety_pct\n",
        "\n",
        "        if variation > 0:\n",
        "            target_price = price_open + expected_move - security\n",
        "            # Vérifier si le target est atteint dans le High\n",
        "            exit_price = min(target_price, price_high)\n",
        "            if exit_price < target_price:\n",
        "                exit_price = price_next_close\n",
        "        else:\n",
        "            target_price = price_open + expected_move + security\n",
        "            exit_price = max(target_price, price_low)\n",
        "            if exit_price > target_price:\n",
        "                exit_price = price_next_close\n",
        "\n",
        "        # Calcul LONG\n",
        "        if variation > 0:\n",
        "            position = wallet * lever\n",
        "            borrowed = wallet * (lever - 1)\n",
        "            units = position / price_open\n",
        "            wallet = (units * exit_price) - borrowed\n",
        "\n",
        "        # Calcul SHORT\n",
        "        else:\n",
        "            position = wallet * lever\n",
        "            borrowed = wallet * (lever - 1)\n",
        "            units = position / price_open\n",
        "            sell_proceeds = units * price_open\n",
        "            buy_back = units * exit_price\n",
        "            wallet = wallet + sell_proceeds - buy_back - borrowed\n",
        "\n",
        "        print(f\"Step {i}, {str_variation}, prix sortie: {exit_price:.2f}, solde: {wallet:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8Kr0k7MIqS",
        "outputId": "8316f584-78df-4482-e4a1-c4a767d089e1"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, monte, prix sortie: 108784.33, solde: 9.98\n",
            "Step 1, monte, prix sortie: 108774.23, solde: 9.94\n",
            "Step 3, baisse, prix sortie: 109240.00, solde: 9.90\n",
            "Step 4, baisse, prix sortie: 109217.64, solde: 9.88\n",
            "Step 5, baisse, prix sortie: 108627.74, solde: 9.93\n",
            "Step 6, baisse, prix sortie: 108511.29, solde: 9.99\n",
            "Step 7, baisse, prix sortie: 108574.76, solde: 10.02\n",
            "Step 8, baisse, prix sortie: 109237.42, solde: 9.89\n",
            "Step 9, baisse, prix sortie: 109040.36, solde: 9.83\n",
            "Step 10, baisse, prix sortie: 109313.00, solde: 9.83\n",
            "Step 11, baisse, prix sortie: 110246.01, solde: 9.72\n",
            "Step 12, monte, prix sortie: 109991.82, solde: 9.78\n",
            "Step 13, monte, prix sortie: 110310.56, solde: 9.79\n",
            "Step 14, monte, prix sortie: 110209.32, solde: 9.78\n",
            "Step 15, monte, prix sortie: 110376.63, solde: 9.78\n",
            "Step 16, monte, prix sortie: 110233.92, solde: 9.78\n",
            "Step 17, monte, prix sortie: 110360.00, solde: 9.78\n",
            "Step 18, monte, prix sortie: 110450.56, solde: 9.80\n",
            "Step 19, monte, prix sortie: 110246.00, solde: 9.79\n",
            "Step 21, baisse, prix sortie: 110136.11, solde: 9.80\n",
            "Step 22, monte, prix sortie: 110459.60, solde: 9.87\n",
            "Step 23, monte, prix sortie: 109341.53, solde: 9.91\n",
            "Step 24, monte, prix sortie: 111414.43, solde: 9.94\n",
            "Step 25, monte, prix sortie: 110785.85, solde: 9.89\n",
            "Step 26, monte, prix sortie: 110985.28, solde: 9.90\n",
            "Step 27, monte, prix sortie: 110646.47, solde: 9.89\n",
            "Step 28, baisse, prix sortie: 110806.00, solde: 9.90\n",
            "Step 29, baisse, prix sortie: 111418.49, solde: 9.83\n",
            "Step 30, baisse, prix sortie: 111129.57, solde: 9.80\n",
            "Step 31, baisse, prix sortie: 111259.99, solde: 9.81\n",
            "Step 32, baisse, prix sortie: 111240.01, solde: 9.80\n",
            "Step 33, baisse, prix sortie: 111339.98, solde: 9.80\n",
            "Step 34, baisse, prix sortie: 111176.94, solde: 9.80\n",
            "Step 36, monte, prix sortie: 111054.01, solde: 9.79\n",
            "Step 37, monte, prix sortie: 111020.68, solde: 9.76\n",
            "Step 38, monte, prix sortie: 110685.57, solde: 9.73\n",
            "Step 39, monte, prix sortie: 110724.00, solde: 9.70\n",
            "Step 40, monte, prix sortie: 111056.29, solde: 9.74\n",
            "Step 41, baisse, prix sortie: 111019.99, solde: 9.71\n",
            "Step 42, baisse, prix sortie: 111312.28, solde: 9.69\n",
            "Step 43, baisse, prix sortie: 111449.99, solde: 9.65\n",
            "Step 44, baisse, prix sortie: 111437.77, solde: 9.64\n",
            "Step 45, baisse, prix sortie: 111112.00, solde: 9.67\n",
            "Step 46, baisse, prix sortie: 111475.07, solde: 9.67\n",
            "Step 47, baisse, prix sortie: 112261.37, solde: 9.57\n",
            "Step 48, baisse, prix sortie: 112222.74, solde: 9.50\n",
            "Step 49, baisse, prix sortie: 111858.66, solde: 9.54\n",
            "Step 50, baisse, prix sortie: 112312.64, solde: 9.53\n",
            "Step 51, baisse, prix sortie: 112000.00, solde: 9.52\n",
            "Step 52, baisse, prix sortie: 111984.55, solde: 9.55\n",
            "Step 53, baisse, prix sortie: 112211.31, solde: 9.53\n",
            "Step 54, baisse, prix sortie: 111989.67, solde: 9.55\n",
            "Step 55, baisse, prix sortie: 111947.48, solde: 9.57\n",
            "Step 56, baisse, prix sortie: 111705.71, solde: 9.59\n",
            "Step 57, baisse, prix sortie: 112065.61, solde: 9.58\n",
            "Step 58, baisse, prix sortie: 111947.48, solde: 9.56\n",
            "Step 59, baisse, prix sortie: 111720.59, solde: 9.59\n",
            "Step 60, monte, prix sortie: 111148.97, solde: 9.52\n",
            "Step 61, monte, prix sortie: 110917.45, solde: 9.48\n",
            "Step 63, baisse, prix sortie: 110482.31, solde: 9.51\n",
            "Step 64, baisse, prix sortie: 110463.36, solde: 9.53\n",
            "Step 65, baisse, prix sortie: 110640.97, solde: 9.51\n",
            "Step 66, baisse, prix sortie: 110815.04, solde: 9.48\n",
            "Step 67, baisse, prix sortie: 110628.86, solde: 9.48\n",
            "Step 68, baisse, prix sortie: 110810.00, solde: 9.48\n",
            "Step 69, baisse, prix sortie: 110933.94, solde: 9.45\n",
            "Step 70, baisse, prix sortie: 110464.00, solde: 9.48\n",
            "Step 71, baisse, prix sortie: 109786.53, solde: 9.58\n",
            "Step 72, baisse, prix sortie: 111445.00, solde: 9.50\n",
            "Step 73, baisse, prix sortie: 111574.50, solde: 9.47\n",
            "Step 74, monte, prix sortie: 111560.09, solde: 9.48\n",
            "Step 75, monte, prix sortie: 112042.67, solde: 9.52\n",
            "Step 76, monte, prix sortie: 112446.90, solde: 9.57\n",
            "Step 77, monte, prix sortie: 112303.87, solde: 9.51\n",
            "Step 78, monte, prix sortie: 112256.36, solde: 9.48\n",
            "Step 79, monte, prix sortie: 112354.00, solde: 9.49\n",
            "Step 80, monte, prix sortie: 112891.13, solde: 9.54\n",
            "Step 81, monte, prix sortie: 113015.61, solde: 9.60\n",
            "Step 82, monte, prix sortie: 110569.99, solde: 9.37\n",
            "Step 83, monte, prix sortie: 110716.82, solde: 9.18\n",
            "Step 84, monte, prix sortie: 110864.10, solde: 9.20\n",
            "Step 85, monte, prix sortie: 110608.18, solde: 9.19\n",
            "Step 86, monte, prix sortie: 111198.78, solde: 9.22\n",
            "Step 87, baisse, prix sortie: 111614.54, solde: 9.14\n",
            "Step 88, baisse, prix sortie: 111082.22, solde: 9.15\n",
            "Step 89, baisse, prix sortie: 110876.12, solde: 9.18\n",
            "Step 90, baisse, prix sortie: 110714.00, solde: 9.21\n",
            "Step 91, baisse, prix sortie: 110752.83, solde: 9.22\n",
            "Step 92, baisse, prix sortie: 110825.60, solde: 9.21\n",
            "Step 93, baisse, prix sortie: 110952.76, solde: 9.19\n",
            "Step 94, baisse, prix sortie: 110695.06, solde: 9.20\n",
            "Step 95, baisse, prix sortie: 110773.62, solde: 9.22\n",
            "Step 96, baisse, prix sortie: 110781.02, solde: 9.21\n",
            "Step 97, baisse, prix sortie: 110832.58, solde: 9.21\n",
            "Step 98, baisse, prix sortie: 110936.82, solde: 9.19\n",
            "Step 99, baisse, prix sortie: 110807.77, solde: 9.20\n",
            "Step 100, baisse, prix sortie: 110384.15, solde: 9.24\n",
            "Step 101, baisse, prix sortie: 110267.99, solde: 9.29\n",
            "Step 102, baisse, prix sortie: 110157.41, solde: 9.31\n",
            "Step 103, baisse, prix sortie: 110228.00, solde: 9.31\n",
            "Step 104, baisse, prix sortie: 110038.41, solde: 9.32\n",
            "Step 105, baisse, prix sortie: 110167.00, solde: 9.32\n",
            "Step 106, baisse, prix sortie: 110201.00, solde: 9.31\n",
            "Step 107, baisse, prix sortie: 110170.55, solde: 9.31\n",
            "Step 108, baisse, prix sortie: 110187.97, solde: 9.31\n",
            "Step 109, baisse, prix sortie: 110356.75, solde: 9.30\n",
            "Step 110, baisse, prix sortie: 110546.66, solde: 9.27\n",
            "Step 111, baisse, prix sortie: 110666.24, solde: 9.24\n",
            "Step 112, baisse, prix sortie: 110629.15, solde: 9.23\n",
            "Step 113, baisse, prix sortie: 110557.76, solde: 9.24\n",
            "Step 114, baisse, prix sortie: 110649.44, solde: 9.24\n",
            "Step 115, baisse, prix sortie: 110504.15, solde: 9.24\n",
            "Step 116, monte, prix sortie: 110753.42, solde: 9.25\n",
            "Step 117, monte, prix sortie: 111071.25, solde: 9.30\n",
            "Step 118, monte, prix sortie: 111115.98, solde: 9.33\n",
            "Step 119, monte, prix sortie: 111225.02, solde: 9.34\n",
            "Step 120, monte, prix sortie: 111292.13, solde: 9.36\n",
            "Step 121, monte, prix sortie: 111115.92, solde: 9.35\n",
            "Step 122, monte, prix sortie: 111214.62, solde: 9.34\n",
            "Step 123, monte, prix sortie: 111145.59, solde: 9.35\n",
            "Step 124, monte, prix sortie: 111053.76, solde: 9.33\n",
            "Step 125, monte, prix sortie: 111259.99, solde: 9.36\n",
            "Step 126, monte, prix sortie: 111330.30, solde: 9.38\n",
            "Step 128, monte, prix sortie: 111250.01, solde: 9.37\n",
            "Step 129, baisse, prix sortie: 111137.34, solde: 9.37\n",
            "Step 130, baisse, prix sortie: 110837.96, solde: 9.40\n",
            "Step 133, monte, prix sortie: 111052.11, solde: 9.41\n",
            "Step 134, baisse, prix sortie: 110991.57, solde: 9.44\n",
            "Step 136, baisse, prix sortie: 111113.26, solde: 9.42\n",
            "Step 137, baisse, prix sortie: 111280.39, solde: 9.40\n",
            "Step 138, baisse, prix sortie: 112052.43, solde: 9.32\n",
            "Step 141, monte, prix sortie: 112227.81, solde: 9.34\n",
            "Step 142, monte, prix sortie: 112534.65, solde: 9.39\n",
            "Step 143, monte, prix sortie: 112398.00, solde: 9.37\n",
            "Step 144, baisse, prix sortie: 112290.25, solde: 9.40\n",
            "Step 145, monte, prix sortie: 112477.01, solde: 9.41\n",
            "Step 147, baisse, prix sortie: 112165.47, solde: 9.43\n",
            "Step 148, baisse, prix sortie: 112326.45, solde: 9.41\n",
            "Step 149, baisse, prix sortie: 112236.71, solde: 9.39\n",
            "Step 150, baisse, prix sortie: 112065.23, solde: 9.41\n",
            "Step 151, baisse, prix sortie: 111524.01, solde: 9.47\n",
            "Step 152, baisse, prix sortie: 111364.73, solde: 9.53\n",
            "Step 153, baisse, prix sortie: 111330.71, solde: 9.56\n",
            "Step 154, monte, prix sortie: 111773.85, solde: 9.59\n",
            "Step 156, monte, prix sortie: 112433.59, solde: 9.55\n",
            "Step 157, monte, prix sortie: 111411.13, solde: 9.44\n",
            "Step 158, monte, prix sortie: 111545.88, solde: 9.48\n",
            "Step 159, baisse, prix sortie: 111520.43, solde: 9.47\n",
            "Step 160, baisse, prix sortie: 111577.31, solde: 9.47\n",
            "Step 161, baisse, prix sortie: 111792.33, solde: 9.45\n",
            "Step 162, baisse, prix sortie: 112553.65, solde: 9.36\n",
            "Step 163, baisse, prix sortie: 112370.08, solde: 9.32\n",
            "Step 164, monte, prix sortie: 112274.29, solde: 9.29\n",
            "Step 165, monte, prix sortie: 112270.01, solde: 9.28\n",
            "Step 166, monte, prix sortie: 112299.99, solde: 9.29\n",
            "Step 167, monte, prix sortie: 113299.55, solde: 9.37\n",
            "Step 168, monte, prix sortie: 113853.99, solde: 9.36\n",
            "Step 169, monte, prix sortie: 113759.89, solde: 9.35\n",
            "Step 170, monte, prix sortie: 113738.01, solde: 9.34\n",
            "Step 171, baisse, prix sortie: 113605.93, solde: 9.35\n",
            "Step 172, baisse, prix sortie: 113462.18, solde: 9.38\n",
            "Step 173, baisse, prix sortie: 113566.39, solde: 9.38\n",
            "Step 174, baisse, prix sortie: 113842.53, solde: 9.36\n",
            "Step 175, baisse, prix sortie: 113881.20, solde: 9.33\n",
            "Step 176, baisse, prix sortie: 113960.00, solde: 9.32\n",
            "Step 177, baisse, prix sortie: 113885.70, solde: 9.32\n",
            "Step 178, baisse, prix sortie: 113903.23, solde: 9.33\n",
            "Step 179, monte, prix sortie: 113819.02, solde: 9.32\n",
            "Step 180, monte, prix sortie: 114400.01, solde: 9.36\n",
            "Step 181, monte, prix sortie: 114158.29, solde: 9.39\n",
            "Step 182, monte, prix sortie: 114266.00, solde: 9.38\n",
            "Step 183, monte, prix sortie: 114324.64, solde: 9.39\n",
            "Step 184, monte, prix sortie: 114083.58, solde: 9.38\n",
            "Step 185, monte, prix sortie: 114049.39, solde: 9.35\n",
            "Step 186, monte, prix sortie: 113895.29, solde: 9.34\n",
            "Step 187, monte, prix sortie: 114062.32, solde: 9.34\n",
            "Step 188, monte, prix sortie: 113999.99, solde: 9.35\n",
            "Step 189, monte, prix sortie: 114419.84, solde: 9.38\n",
            "Step 190, monte, prix sortie: 114388.44, solde: 9.41\n",
            "Step 191, monte, prix sortie: 114280.20, solde: 9.43\n",
            "Step 192, monte, prix sortie: 114180.31, solde: 9.40\n",
            "Step 193, baisse, prix sortie: 114222.44, solde: 9.42\n",
            "Step 194, monte, prix sortie: 114589.84, solde: 9.45\n",
            "Step 195, monte, prix sortie: 114312.35, solde: 9.44\n",
            "Step 196, monte, prix sortie: 114419.99, solde: 9.42\n",
            "Step 200, baisse, prix sortie: 115482.69, solde: 9.34\n",
            "Step 201, monte, prix sortie: 115392.35, solde: 9.37\n",
            "Step 202, monte, prix sortie: 115991.14, solde: 9.41\n",
            "Step 203, monte, prix sortie: 115391.00, solde: 9.37\n",
            "Step 204, monte, prix sortie: 115194.14, solde: 9.36\n",
            "Step 205, monte, prix sortie: 115359.99, solde: 9.35\n",
            "Step 206, monte, prix sortie: 115612.84, solde: 9.39\n",
            "Step 207, monte, prix sortie: 115318.00, solde: 9.38\n",
            "Step 208, monte, prix sortie: 115086.70, solde: 9.34\n",
            "Step 209, monte, prix sortie: 115048.00, solde: 9.32\n",
            "Step 210, monte, prix sortie: 115048.01, solde: 9.32\n",
            "Step 211, monte, prix sortie: 114980.85, solde: 9.31\n",
            "Step 212, monte, prix sortie: 114913.45, solde: 9.30\n",
            "Step 213, monte, prix sortie: 115083.97, solde: 9.31\n",
            "Step 214, monte, prix sortie: 115087.31, solde: 9.32\n",
            "Step 215, baisse, prix sortie: 115260.00, solde: 9.31\n",
            "Step 216, baisse, prix sortie: 115121.18, solde: 9.31\n",
            "Step 217, baisse, prix sortie: 115495.56, solde: 9.29\n",
            "Step 218, baisse, prix sortie: 115815.16, solde: 9.24\n",
            "Step 219, baisse, prix sortie: 116486.18, solde: 9.16\n",
            "Step 220, monte, prix sortie: 116077.82, solde: 9.18\n",
            "Step 221, monte, prix sortie: 116157.33, solde: 9.15\n",
            "Step 222, monte, prix sortie: 115865.89, solde: 9.09\n",
            "Step 223, monte, prix sortie: 116027.46, solde: 9.08\n",
            "Step 225, monte, prix sortie: 116209.32, solde: 9.10\n",
            "Step 226, monte, prix sortie: 115764.30, solde: 9.07\n",
            "Step 227, monte, prix sortie: 115886.17, solde: 9.05\n",
            "Step 228, monte, prix sortie: 115957.00, solde: 9.06\n",
            "Step 229, monte, prix sortie: 115698.40, solde: 9.05\n",
            "Step 230, monte, prix sortie: 115704.04, solde: 9.03\n",
            "Step 231, monte, prix sortie: 115749.99, solde: 9.03\n",
            "Step 232, monte, prix sortie: 115778.71, solde: 9.04\n",
            "Step 233, monte, prix sortie: 115978.01, solde: 9.06\n",
            "Step 234, baisse, prix sortie: 116035.33, solde: 9.04\n",
            "Step 235, baisse, prix sortie: 115937.99, solde: 9.04\n",
            "Step 236, baisse, prix sortie: 115974.11, solde: 9.05\n",
            "Step 237, baisse, prix sortie: 116002.91, solde: 9.04\n",
            "Step 238, baisse, prix sortie: 115761.05, solde: 9.06\n",
            "Step 239, baisse, prix sortie: 115797.68, solde: 9.07\n",
            "Step 240, baisse, prix sortie: 115768.68, solde: 9.07\n",
            "Step 241, baisse, prix sortie: 115334.00, solde: 9.11\n",
            "Step 242, baisse, prix sortie: 115571.78, solde: 9.12\n",
            "Step 243, baisse, prix sortie: 115871.58, solde: 9.08\n",
            "Step 244, baisse, prix sortie: 115918.29, solde: 9.08\n",
            "Step 245, baisse, prix sortie: 115935.60, solde: 9.08\n",
            "Step 247, baisse, prix sortie: 115852.95, solde: 9.08\n",
            "Step 248, monte, prix sortie: 115679.98, solde: 9.06\n",
            "Step 249, monte, prix sortie: 115750.99, solde: 9.05\n",
            "Step 250, monte, prix sortie: 115860.01, solde: 9.07\n",
            "Step 251, monte, prix sortie: 115734.23, solde: 9.06\n",
            "Step 252, monte, prix sortie: 115805.39, solde: 9.06\n",
            "Step 253, monte, prix sortie: 115933.40, solde: 9.08\n",
            "Step 254, monte, prix sortie: 116052.09, solde: 9.09\n",
            "Step 255, monte, prix sortie: 116027.26, solde: 9.10\n",
            "Step 256, monte, prix sortie: 115794.91, solde: 9.08\n",
            "Step 257, monte, prix sortie: 115776.31, solde: 9.06\n",
            "Step 258, monte, prix sortie: 115348.10, solde: 9.03\n",
            "Step 259, monte, prix sortie: 115401.75, solde: 9.00\n",
            "Step 260, monte, prix sortie: 115224.01, solde: 8.99\n",
            "Step 261, monte, prix sortie: 115480.00, solde: 8.99\n",
            "Step 262, baisse, prix sortie: 115557.65, solde: 8.97\n",
            "Step 263, baisse, prix sortie: 115388.21, solde: 8.98\n",
            "Step 264, baisse, prix sortie: 115634.99, solde: 8.97\n",
            "Step 265, baisse, prix sortie: 115802.16, solde: 8.94\n",
            "Step 266, baisse, prix sortie: 116058.88, solde: 8.90\n",
            "Step 267, baisse, prix sortie: 116009.61, solde: 8.89\n",
            "Step 268, baisse, prix sortie: 115206.03, solde: 8.95\n",
            "Step 269, baisse, prix sortie: 114992.58, solde: 9.03\n",
            "Step 270, baisse, prix sortie: 115231.69, solde: 9.04\n",
            "Step 272, monte, prix sortie: 115445.45, solde: 9.05\n",
            "Step 273, monte, prix sortie: 115847.47, solde: 9.09\n",
            "Step 274, baisse, prix sortie: 116520.00, solde: 9.01\n",
            "Step 275, baisse, prix sortie: 116129.99, solde: 9.00\n",
            "Step 276, baisse, prix sortie: 116279.14, solde: 9.02\n",
            "Step 277, monte, prix sortie: 114737.27, solde: 8.91\n",
            "Step 278, monte, prix sortie: 114868.59, solde: 8.84\n",
            "Step 279, monte, prix sortie: 114769.04, solde: 8.84\n",
            "Step 280, monte, prix sortie: 115070.00, solde: 8.86\n",
            "Step 281, monte, prix sortie: 114721.04, solde: 8.85\n",
            "Step 282, baisse, prix sortie: 114595.19, solde: 8.89\n",
            "Step 283, baisse, prix sortie: 114679.56, solde: 8.89\n",
            "Step 284, baisse, prix sortie: 114842.90, solde: 8.88\n",
            "Step 285, baisse, prix sortie: 114662.57, solde: 8.88\n",
            "Step 286, baisse, prix sortie: 115120.03, solde: 8.86\n",
            "Step 287, baisse, prix sortie: 115307.79, solde: 8.81\n",
            "Step 288, baisse, prix sortie: 115307.78, solde: 8.79\n",
            "Step 289, baisse, prix sortie: 115379.99, solde: 8.79\n",
            "Step 290, baisse, prix sortie: 115528.00, solde: 8.77\n",
            "Step 291, baisse, prix sortie: 115288.01, solde: 8.78\n",
            "Step 292, baisse, prix sortie: 115349.71, solde: 8.79\n",
            "Step 293, baisse, prix sortie: 115088.66, solde: 8.81\n",
            "Step 294, baisse, prix sortie: 115024.24, solde: 8.83\n",
            "Step 295, monte, prix sortie: 115034.47, solde: 8.83\n",
            "Step 296, monte, prix sortie: 115307.25, solde: 8.85\n",
            "Step 297, monte, prix sortie: 115503.01, solde: 8.89\n",
            "Step 298, monte, prix sortie: 115936.65, solde: 8.93\n",
            "Step 299, monte, prix sortie: 115770.35, solde: 8.96\n",
            "Step 300, monte, prix sortie: 115840.00, solde: 8.95\n",
            "Step 301, monte, prix sortie: 115658.76, solde: 8.94\n",
            "Step 302, monte, prix sortie: 115477.27, solde: 8.91\n",
            "Step 303, monte, prix sortie: 115372.46, solde: 8.89\n",
            "Step 304, monte, prix sortie: 115287.83, solde: 8.87\n",
            "Step 305, monte, prix sortie: 115439.36, solde: 8.88\n",
            "Step 306, monte, prix sortie: 115200.00, solde: 8.87\n",
            "Step 308, baisse, prix sortie: 115905.88, solde: 8.82\n",
            "Step 309, monte, prix sortie: 116007.70, solde: 8.87\n",
            "Step 310, baisse, prix sortie: 116461.54, solde: 8.83\n",
            "Step 311, monte, prix sortie: 116209.05, solde: 8.84\n",
            "Step 312, monte, prix sortie: 116800.12, solde: 8.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor"
      ],
      "metadata": {
        "id": "SLNIu20NM0t6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "994453fb-2208-4521-f632-f22d0be0c494"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1302930888.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "P7YODgujgJFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8sjtHWUabn5",
        "outputId": "28ad899f-69cd-4ead-db87-9fa7333891be"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "xRkVsGrXaf3i"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
        "print(torch.cuda.memory_reserved() / 1024**2, \"MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gacnE5lOaiTZ",
        "outputId": "99606fd3-e0f4-43fe-80ae-9d5fc05dd239"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "551.3447265625 MB\n",
            "584.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kF0XUOqXalHI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
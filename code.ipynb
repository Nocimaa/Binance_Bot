{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNXLcSoxJk33eSiO+RLspVc","include_colab_link":true},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Nocimaa/Binance_Bot/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github","colab_type":"text"}},{"cell_type":"code","source":"!wget \"https://raw.githubusercontent.com/Nocimaa/Binance_Bot/refs/heads/main/btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oiTAtF6gJgf","outputId":"e693ffd2-78cc-4ba5-f53a-4f4cb4214b17","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:43.917809Z","iopub.execute_input":"2025-09-19T12:02:43.918058Z","iopub.status.idle":"2025-09-19T12:02:46.298886Z","shell.execute_reply.started":"2025-09-19T12:02:43.918037Z","shell.execute_reply":"2025-09-19T12:02:46.298096Z"}},"outputs":[{"name":"stdout","text":"--2025-09-19 12:02:43--  https://raw.githubusercontent.com/Nocimaa/Binance_Bot/refs/heads/main/btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 28620838 (27M) [text/plain]\nSaving to: ‘btc_1h_adx_2017-08-17_to_2025-09-17(in).csv’\n\nbtc_1h_adx_2017-08- 100%[===================>]  27.29M  --.-KB/s    in 0.07s   \n\n2025-09-19 12:02:46 (405 MB/s) - ‘btc_1h_adx_2017-08-17_to_2025-09-17(in).csv’ saved [28620838/28620838]\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n#Test","metadata":{"id":"en6-eWhqgiaB","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:46.300152Z","iopub.execute_input":"2025-09-19T12:02:46.300457Z","iopub.status.idle":"2025-09-19T12:02:46.562333Z","shell.execute_reply.started":"2025-09-19T12:02:46.300422Z","shell.execute_reply":"2025-09-19T12:02:46.561826Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"base = pd.read_csv(\"btc_1h_adx_2017-08-17_to_2025-09-17(in).csv\")\n\ndf = base[base[\"timestamp\"] < \"2025-09-01 00:00:00+02:00\"]\npredict_df = base[base[\"timestamp\"] >= \"2025-09-01 00:00:00+02:00\"]\n\ndef max_log_return(close, high, low):\n    log_high = np.log(high / close)\n    log_low = np.log(low / close)\n    return log_high if abs(log_high) > abs(log_low) else log_low\n\ndef preprocessing(df, index_label=True):\n  if index_label:\n    # df[\"label\"] = np.log()\n    df[\"label\"] = [\n      max_log_return(c, h, l)\n      for c, h, l in zip(df[\"close\"], df[\"high\"].shift(-1), df[\"low\"].shift(-1))\n    ]\n  df = df.drop(\"timestamp\", axis=1)\n  # df = df.drop(\"close\", axis=1)\n\n\n  features = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"ATR14\",\"MACD\"]\n  window = 3\n  for f in features:\n      for w in range(1, window+1):\n          df[f\"{f}_lag{w}\"] = df[f].shift(w)\n\n\n  df.dropna(inplace=True)\n  return df\n\ndf = preprocessing(df)\npredict_df = preprocessing(predict_df, index_label=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmOryAAwgtC7","outputId":"29aa80b5-93e8-4632-c390-72cd2f0624bc","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:46.563030Z","iopub.execute_input":"2025-09-19T12:02:46.563439Z","iopub.status.idle":"2025-09-19T12:02:47.206264Z","shell.execute_reply.started":"2025-09-19T12:02:46.563414Z","shell.execute_reply":"2025-09-19T12:02:47.205396Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3372430355.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[\"label\"] = [\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df.head()\ndf[\"label\"]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"y1U0Miu7gw_b","outputId":"36e1650d-0aac-4c49-c858-799cdc10fbb3","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:47.207522Z","iopub.execute_input":"2025-09-19T12:02:47.207763Z","iopub.status.idle":"2025-09-19T12:02:47.215286Z","shell.execute_reply.started":"2025-09-19T12:02:47.207746Z","shell.execute_reply":"2025-09-19T12:02:47.214771Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"3       -0.021783\n4       -0.005761\n5       -0.016528\n6        0.017963\n7       -0.017351\n           ...   \n70249    0.000652\n70250    0.002233\n70251   -0.002113\n70252    0.001724\n70253   -0.001475\nName: label, Length: 70251, dtype: float64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"y = df[\"label\"]\nX = df.drop(\"label\", axis=1)","metadata":{"id":"P16J24ChiDe9","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:47.216011Z","iopub.execute_input":"2025-09-19T12:02:47.216711Z","iopub.status.idle":"2025-09-19T12:02:47.237901Z","shell.execute_reply.started":"2025-09-19T12:02:47.216682Z","shell.execute_reply":"2025-09-19T12:02:47.237370Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.feature_selection import SelectKBest, f_regression\nfrom sklearn.preprocessing import StandardScaler\n\nk = 20\nselector = SelectKBest(score_func=f_regression, k=k)\nX_new = selector.fit_transform(X, y)\n\nscaler = StandardScaler()\nX_new = scaler.fit_transform(X_new)","metadata":{"id":"6TOXhziajFuL","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:47.293398Z","iopub.execute_input":"2025-09-19T12:02:47.293651Z","iopub.status.idle":"2025-09-19T12:02:48.163360Z","shell.execute_reply.started":"2025-09-19T12:02:47.293628Z","shell.execute_reply":"2025-09-19T12:02:48.162571Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)","metadata":{"id":"zdUb3aTujKqj","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:48.164704Z","iopub.execute_input":"2025-09-19T12:02:48.165116Z","iopub.status.idle":"2025-09-19T12:02:48.181998Z","shell.execute_reply.started":"2025-09-19T12:02:48.165088Z","shell.execute_reply":"2025-09-19T12:02:48.181260Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n\ndef create_sequences(X, y, seq_len=50):\n    Xs, ys = [], []\n    for i in range(len(X) - seq_len):\n        Xs.append(X[i:i+seq_len])\n        ys.append(y[i+seq_len])\n    return np.array(Xs), np.array(ys)\n\n\ny_scaler = StandardScaler()\ny_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1,1))\ny_test_scaled  = y_scaler.transform(y_test.values.reshape(-1,1))\n\nseq_len = 5  # tu peux ajuster\n\nX_train_seq, y_train_seq = create_sequences(X_train, y_train_scaled, seq_len)\nX_test_seq, y_test_seq   = create_sequences(X_test,  y_test_scaled,  seq_len)\n\n\nX_train_tensor = torch.tensor(X_train_seq, dtype=torch.float32).to(device)\ny_train_tensor = torch.tensor(y_train_seq, dtype=torch.float32).to(device)\n\nX_test_tensor  = torch.tensor(X_test_seq, dtype=torch.float32).to(device)\ny_test_tensor  = torch.tensor(y_test_seq, dtype=torch.float32).to(device)","metadata":{"id":"B9A7VhBZj5ty","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:02:48.182867Z","iopub.execute_input":"2025-09-19T12:02:48.183149Z","iopub.status.idle":"2025-09-19T12:02:52.615361Z","shell.execute_reply.started":"2025-09-19T12:02:48.183122Z","shell.execute_reply":"2025-09-19T12:02:52.614719Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nclass LSTMNet(nn.Module):\n    def __init__(self, input_dim, hidden_dim=64, num_layers=3, dropout=0.25):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.num_layers = num_layers\n\n        # LSTM empilé\n        self.lstm = nn.LSTM(\n            input_dim,\n            hidden_dim,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout\n        )\n\n        # Normalisation + Fully Connected\n        self.bn = nn.BatchNorm1d(hidden_dim)\n        self.fc1 = nn.Linear(hidden_dim, 64)\n        self.fc2 = nn.Linear(64, 1)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # x: (batch, seq_len, input_dim\n\n        out, _ = self.lstm(x)  # out: (batch, seq_len, hidden_dim)\n        out = out[:, -1, :]    # garder le dernier état\n        out = self.bn(out)\n        out = F.relu(self.fc1(out))\n        out = self.dropout(out)\n        return self.fc2(out)\n\n\nmodel = LSTMNet(input_dim=k)\nmodel = model.to(device)","metadata":{"id":"aygb4S84j-de","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:04:03.534531Z","iopub.execute_input":"2025-09-19T12:04:03.535197Z","iopub.status.idle":"2025-09-19T12:04:03.545887Z","shell.execute_reply.started":"2025-09-19T12:04:03.535176Z","shell.execute_reply":"2025-09-19T12:04:03.545143Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"criterion = nn.SmoothL1Loss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nepochs = 100\nbatch_size = 256","metadata":{"id":"zsVOmjhEkKJH","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:04:07.364128Z","iopub.execute_input":"2025-09-19T12:04:07.364731Z","iopub.status.idle":"2025-09-19T12:04:07.369257Z","shell.execute_reply.started":"2025-09-19T12:04:07.364705Z","shell.execute_reply":"2025-09-19T12:04:07.368637Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(epochs):\n    permutation = torch.randperm(X_train_tensor.size(0))\n    for i in range(0, X_train_tensor.size(0), batch_size):\n        indices = permutation[i:i+batch_size]\n        batch_x, batch_y = X_train_tensor[indices], y_train_tensor[indices]\n\n        optimizer.zero_grad()\n        outputs = model(batch_x)\n        loss = criterion(outputs, batch_y)\n        loss.backward()\n        optimizer.step()\n\n    # Évaluation train\n    with torch.no_grad():\n        preds = model(X_train_tensor)\n        mse = criterion(preds, y_train_tensor).item()\n    print(f\"Epoch {epoch+1}/{epochs}, Train MSE={mse:.4f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4vTCmLskcR7","outputId":"4d76a5f1-f6cf-41b7-e3a9-6433283462aa","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:04:07.744538Z","iopub.execute_input":"2025-09-19T12:04:07.745313Z","iopub.status.idle":"2025-09-19T12:05:22.203468Z","shell.execute_reply.started":"2025-09-19T12:04:07.745285Z","shell.execute_reply":"2025-09-19T12:05:22.202796Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100, Train MSE=0.3317\nEpoch 2/100, Train MSE=0.3311\nEpoch 3/100, Train MSE=0.3307\nEpoch 4/100, Train MSE=0.3307\nEpoch 5/100, Train MSE=0.3305\nEpoch 6/100, Train MSE=0.3305\nEpoch 7/100, Train MSE=0.3305\nEpoch 8/100, Train MSE=0.3304\nEpoch 9/100, Train MSE=0.3305\nEpoch 10/100, Train MSE=0.3304\nEpoch 11/100, Train MSE=0.3305\nEpoch 12/100, Train MSE=0.3306\nEpoch 13/100, Train MSE=0.3302\nEpoch 14/100, Train MSE=0.3303\nEpoch 15/100, Train MSE=0.3304\nEpoch 16/100, Train MSE=0.3302\nEpoch 17/100, Train MSE=0.3298\nEpoch 18/100, Train MSE=0.3298\nEpoch 19/100, Train MSE=0.3299\nEpoch 20/100, Train MSE=0.3294\nEpoch 21/100, Train MSE=0.3295\nEpoch 22/100, Train MSE=0.3289\nEpoch 23/100, Train MSE=0.3293\nEpoch 24/100, Train MSE=0.3280\nEpoch 25/100, Train MSE=0.3274\nEpoch 26/100, Train MSE=0.3272\nEpoch 27/100, Train MSE=0.3266\nEpoch 28/100, Train MSE=0.3258\nEpoch 29/100, Train MSE=0.3249\nEpoch 30/100, Train MSE=0.3245\nEpoch 31/100, Train MSE=0.3242\nEpoch 32/100, Train MSE=0.3230\nEpoch 33/100, Train MSE=0.3227\nEpoch 34/100, Train MSE=0.3217\nEpoch 35/100, Train MSE=0.3205\nEpoch 36/100, Train MSE=0.3205\nEpoch 37/100, Train MSE=0.3187\nEpoch 38/100, Train MSE=0.3185\nEpoch 39/100, Train MSE=0.3168\nEpoch 40/100, Train MSE=0.3155\nEpoch 41/100, Train MSE=0.3145\nEpoch 42/100, Train MSE=0.3135\nEpoch 43/100, Train MSE=0.3127\nEpoch 44/100, Train MSE=0.3124\nEpoch 45/100, Train MSE=0.3101\nEpoch 46/100, Train MSE=0.3096\nEpoch 47/100, Train MSE=0.3086\nEpoch 48/100, Train MSE=0.3074\nEpoch 49/100, Train MSE=0.3073\nEpoch 50/100, Train MSE=0.3049\nEpoch 51/100, Train MSE=0.3040\nEpoch 52/100, Train MSE=0.3034\nEpoch 53/100, Train MSE=0.3017\nEpoch 54/100, Train MSE=0.3008\nEpoch 55/100, Train MSE=0.3000\nEpoch 56/100, Train MSE=0.2987\nEpoch 57/100, Train MSE=0.2974\nEpoch 58/100, Train MSE=0.2962\nEpoch 59/100, Train MSE=0.2951\nEpoch 60/100, Train MSE=0.2940\nEpoch 61/100, Train MSE=0.2942\nEpoch 62/100, Train MSE=0.2923\nEpoch 63/100, Train MSE=0.2911\nEpoch 64/100, Train MSE=0.2908\nEpoch 65/100, Train MSE=0.2893\nEpoch 66/100, Train MSE=0.2883\nEpoch 67/100, Train MSE=0.2881\nEpoch 68/100, Train MSE=0.2860\nEpoch 69/100, Train MSE=0.2864\nEpoch 70/100, Train MSE=0.2840\nEpoch 71/100, Train MSE=0.2833\nEpoch 72/100, Train MSE=0.2823\nEpoch 73/100, Train MSE=0.2819\nEpoch 74/100, Train MSE=0.2802\nEpoch 75/100, Train MSE=0.2798\nEpoch 76/100, Train MSE=0.2782\nEpoch 77/100, Train MSE=0.2774\nEpoch 78/100, Train MSE=0.2768\nEpoch 79/100, Train MSE=0.2760\nEpoch 80/100, Train MSE=0.2747\nEpoch 81/100, Train MSE=0.2728\nEpoch 82/100, Train MSE=0.2738\nEpoch 83/100, Train MSE=0.2727\nEpoch 84/100, Train MSE=0.2717\nEpoch 85/100, Train MSE=0.2712\nEpoch 86/100, Train MSE=0.2692\nEpoch 87/100, Train MSE=0.2696\nEpoch 88/100, Train MSE=0.2682\nEpoch 89/100, Train MSE=0.2682\nEpoch 90/100, Train MSE=0.2672\nEpoch 91/100, Train MSE=0.2668\nEpoch 92/100, Train MSE=0.2647\nEpoch 93/100, Train MSE=0.2644\nEpoch 94/100, Train MSE=0.2639\nEpoch 95/100, Train MSE=0.2631\nEpoch 96/100, Train MSE=0.2617\nEpoch 97/100, Train MSE=0.2613\nEpoch 98/100, Train MSE=0.2600\nEpoch 99/100, Train MSE=0.2595\nEpoch 100/100, Train MSE=0.2597\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nimport numpy as np\nimport torch\n\nwith torch.no_grad():\n    # prédictions sur GPU\n    preds = model(X_test_tensor)\n\n    # ramener sur CPU avant conversion en numpy\n    preds_cpu = preds.cpu().numpy()\n    y_true_cpu = y_test_tensor.cpu().numpy()\n\n    # si tu as utilisé un scaler pour y\n    preds_orig = y_scaler.inverse_transform(preds_cpu)\n    y_true_orig = y_scaler.inverse_transform(y_true_cpu)\n\n    # calcul métriques\n    from sklearn.metrics import mean_squared_error, mean_absolute_error\n    import numpy as np\n\n    mse_test = mean_squared_error(y_true_orig, preds_orig)\n    rmse_test = np.sqrt(mse_test)\n    mae_test = mean_absolute_error(y_true_orig, preds_orig)\n\nprint(f\"\\nTest MSE (original scale) = {mse_test:.4f}\")\nprint(f\"Test RMSE (original scale) = {rmse_test:.4f}\")\nprint(f\"Test MAE (original scale)  = {mae_test:.4f}\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVPjeLlBk8Ft","outputId":"99ca7e40-db29-4a84-a6b7-c8ded8cdf159","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:05:25.584100Z","iopub.execute_input":"2025-09-19T12:05:25.584815Z","iopub.status.idle":"2025-09-19T12:05:25.614677Z","shell.execute_reply.started":"2025-09-19T12:05:25.584788Z","shell.execute_reply":"2025-09-19T12:05:25.614091Z"}},"outputs":[{"name":"stdout","text":"\nTest MSE (original scale) = 0.0002\nTest RMSE (original scale) = 0.0129\nTest MAE (original scale)  = 0.0086\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def predict_new_row(seq_rows, model, selector, scaler_X, scaler_y, feature_columns, device='cpu'):\n    \"\"\"\n    Prédit le label à partir d'une séquence de nouvelles données (LSTM).\n\n    Args:\n        seq_rows (list[pd.Series] ou pd.DataFrame): séquence de lignes (longueur = seq_len)\n        model (torch.nn.Module): modèle PyTorch déjà entraîné\n        selector (sklearn transformer): SelectKBest ou autre\n        scaler_X (StandardScaler): scaler pour X\n        scaler_y (StandardScaler): scaler pour y\n        feature_columns (list): noms des colonnes/features utilisées\n        device (str): 'cpu' ou 'cuda'\n\n    Returns:\n        float: prédiction en échelle originale\n    \"\"\"\n    # 1️⃣ Construire DataFrame à partir de la séquence\n    if isinstance(seq_rows, list):\n        df_seq = pd.DataFrame(seq_rows, columns=feature_columns)\n    elif isinstance(seq_rows, pd.Series):\n        df_seq = pd.DataFrame([seq_rows], columns=feature_columns)\n    else:\n        df_seq = seq_rows.copy()\n\n    # 2️⃣ Supprimer colonne timestamp si présente\n    if \"timestamp\" in df_seq.columns:\n        df_seq = df_seq.drop(columns=[\"timestamp\"])\n\n    # 3️⃣ Appliquer la sélection de features\n    X_new = selector.transform(df_seq)\n\n    # 4️⃣ Normaliser\n    X_new_scaled = scaler_X.transform(X_new)\n\n    # 5️⃣ Convertir en tenseur avec bonne forme (batch=1, seq_len, input_dim)\n    X_tensor = torch.tensor(X_new_scaled, dtype=torch.float32).unsqueeze(0).to(device)\n\n    # 6️⃣ Prédiction\n    model.eval()\n    with torch.no_grad():\n        pred_scaled = model(X_tensor)\n        pred = scaler_y.inverse_transform(pred_scaled.cpu().numpy())\n\n    return float(pred[0][0])\n\n\nseq_len = 5\nseq_input = predict_df.iloc[0:seq_len].drop(columns=[\"label\"])  # lignes 0 à 4\nvariation = predict_new_row(seq_input, model, selector, scaler, y_scaler, X.columns, device)\nprint(\"Prédiction:\", variation)","metadata":{"id":"Zifd7Mo5q_nf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0991fe8e-52e8-4548-c4cc-f446e2460ee9","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:05:29.083761Z","iopub.execute_input":"2025-09-19T12:05:29.084111Z","iopub.status.idle":"2025-09-19T12:05:29.112667Z","shell.execute_reply.started":"2025-09-19T12:05:29.084086Z","shell.execute_reply":"2025-09-19T12:05:29.111926Z"}},"outputs":[{"name":"stdout","text":"Prédiction: 0.004479532595723867\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"id":"ODqHQRJTlY9w"},"outputs":[],"execution_count":190},{"cell_type":"code","source":"df.columns","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"odshoFIBS5L7","outputId":"82303899-415a-49cc-863d-e89bb2b0fe07"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['open', 'high', 'low', 'close', 'volume', 'ADX', '+DI', '-DI', 'ATR14',\n","       'BB_width', 'BB_pctB', 'RSI14', 'StochK', 'StochD', 'MACD',\n","       'MACD_signal', 'ROC', 'OBV', 'Vol_zscore', 'log_ret',\n","       'close_open_ratio', 'high_low_spread', 'hour', 'dayofweek', 'label',\n","       'open_lag1', 'open_lag2', 'open_lag3', 'high_lag1', 'high_lag2',\n","       'high_lag3', 'low_lag1', 'low_lag2', 'low_lag3', 'close_lag1',\n","       'close_lag2', 'close_lag3', 'volume_lag1', 'volume_lag2', 'volume_lag3',\n","       'ATR14_lag1', 'ATR14_lag2', 'ATR14_lag3', 'MACD_lag1', 'MACD_lag2',\n","       'MACD_lag3'],\n","      dtype='object')"]},"metadata":{},"execution_count":191}],"execution_count":191},{"cell_type":"code","source":"t = 0\nwallet = 10\nlever = 1\nfee_rate = 0.0004  # frais Binance typique\nseq_len = 5\nsafety_pct = 0.5 / 100  # % de sécurité relatif à la variation prédite\n\nfor i in range(len(predict_df) - seq_len):\n    seq_input = predict_df.iloc[i:i+seq_len].drop(columns=[\"label\"])\n    variation = predict_new_row(seq_input, model, selector, scaler, y_scaler, X.columns, device)\n\n    if abs(variation) > 0.001:\n        t += 1\n        str_variation = \"baisse\" if variation < 0 else \"monte\"\n\n        price_open = float(predict_df.iloc[i + seq_len - 1]['open'])\n        price_next_close = float(predict_df.iloc[i + seq_len]['close'])\n        price_high = float(predict_df.iloc[i + seq_len]['high'])\n        price_low = float(predict_df.iloc[i + seq_len]['low'])\n\n        # Écart attendu selon la variation\n        expected_move = price_open * variation\n        security = abs(expected_move) * safety_pct\n\n        if variation > 0:\n            target_price = price_open + expected_move - security\n            # Vérifier si le target est atteint dans le High\n            exit_price = min(target_price, price_high)\n            if exit_price < target_price:\n                exit_price = price_next_close\n        else:\n            target_price = price_open + expected_move + security\n            exit_price = max(target_price, price_low)\n            if exit_price > target_price:\n                exit_price = price_next_close\n\n        # Calcul LONG\n        if variation > 0:\n            position = wallet * lever\n            borrowed = wallet * (lever - 1)\n            units = position / price_open\n            wallet = (units * exit_price) - borrowed\n\n        # Calcul SHORT\n        else:\n            position = wallet * lever\n            borrowed = wallet * (lever - 1)\n            units = position / price_open\n            sell_proceeds = units * price_open\n            buy_back = units * exit_price\n            wallet = wallet + sell_proceeds - buy_back - borrowed\n\n        print(f\"Step {i}, {str_variation}, prix sortie: {exit_price:.2f}, solde: {wallet:.2f}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kl8Kr0k7MIqS","outputId":"8316f584-78df-4482-e4a1-c4a767d089e1","trusted":true,"execution":{"iopub.status.busy":"2025-09-19T12:05:33.306480Z","iopub.execute_input":"2025-09-19T12:05:33.307201Z","iopub.status.idle":"2025-09-19T12:05:34.408182Z","shell.execute_reply.started":"2025-09-19T12:05:33.307175Z","shell.execute_reply":"2025-09-19T12:05:34.407527Z"}},"outputs":[{"name":"stdout","text":"Step 0, monte, prix sortie: 108784.33, solde: 9.98\nStep 1, monte, prix sortie: 108774.23, solde: 9.94\nStep 2, monte, prix sortie: 108927.61, solde: 9.96\nStep 3, monte, prix sortie: 109240.00, solde: 10.00\nStep 4, monte, prix sortie: 109217.64, solde: 10.03\nStep 5, monte, prix sortie: 108877.38, solde: 9.99\nStep 7, baisse, prix sortie: 108700.98, solde: 10.01\nStep 8, baisse, prix sortie: 109237.42, solde: 9.88\nStep 10, monte, prix sortie: 109313.00, solde: 9.88\nStep 11, monte, prix sortie: 109646.26, solde: 9.94\nStep 12, monte, prix sortie: 110101.16, solde: 10.01\nStep 13, monte, prix sortie: 110310.56, solde: 10.02\nStep 14, monte, prix sortie: 110209.32, solde: 10.00\nStep 15, monte, prix sortie: 110376.63, solde: 10.01\nStep 16, monte, prix sortie: 110233.92, solde: 10.01\nStep 17, monte, prix sortie: 110360.00, solde: 10.01\nStep 18, monte, prix sortie: 110450.56, solde: 10.03\nStep 19, monte, prix sortie: 110246.00, solde: 10.02\nStep 20, monte, prix sortie: 109733.34, solde: 9.96\nStep 21, monte, prix sortie: 108795.99, solde: 9.82\nStep 22, monte, prix sortie: 109922.27, solde: 9.84\nStep 23, monte, prix sortie: 109406.95, solde: 9.90\nStep 24, monte, prix sortie: 111444.22, solde: 9.92\nStep 25, monte, prix sortie: 110785.85, solde: 9.87\nStep 26, monte, prix sortie: 110914.00, solde: 9.88\nStep 27, monte, prix sortie: 110646.47, solde: 9.87\nStep 28, monte, prix sortie: 110806.00, solde: 9.86\nStep 29, monte, prix sortie: 111084.13, solde: 9.90\nStep 32, baisse, prix sortie: 111240.01, solde: 9.89\nStep 33, baisse, prix sortie: 111339.98, solde: 9.88\nStep 34, monte, prix sortie: 111176.94, solde: 9.87\nStep 35, monte, prix sortie: 111372.00, solde: 9.88\nStep 36, monte, prix sortie: 111054.01, solde: 9.87\nStep 37, monte, prix sortie: 111020.68, solde: 9.83\nStep 38, monte, prix sortie: 110685.57, solde: 9.80\nStep 39, monte, prix sortie: 110724.00, solde: 9.78\nStep 40, monte, prix sortie: 111099.88, solde: 9.81\nStep 41, monte, prix sortie: 111019.99, solde: 9.84\nStep 42, monte, prix sortie: 111312.28, solde: 9.86\nStep 43, monte, prix sortie: 111449.99, solde: 9.90\nStep 44, monte, prix sortie: 111437.77, solde: 9.91\nStep 45, monte, prix sortie: 111700.79, solde: 9.93\nStep 46, monte, prix sortie: 111713.78, solde: 9.95\nStep 47, monte, prix sortie: 111409.08, solde: 9.98\nStep 48, monte, prix sortie: 111797.32, solde: 10.01\nStep 49, monte, prix sortie: 111858.66, solde: 9.97\nStep 50, monte, prix sortie: 112312.64, solde: 9.98\nStep 51, monte, prix sortie: 112275.26, solde: 10.02\nStep 52, monte, prix sortie: 112193.74, solde: 10.01\nStep 53, monte, prix sortie: 112229.94, solde: 10.03\nStep 56, baisse, prix sortie: 111672.05, solde: 10.06\nStep 57, baisse, prix sortie: 112065.61, solde: 10.05\nStep 59, monte, prix sortie: 111450.15, solde: 9.99\nStep 60, monte, prix sortie: 111148.97, solde: 9.92\nStep 61, monte, prix sortie: 110917.45, solde: 9.87\nStep 62, monte, prix sortie: 110653.07, solde: 9.83\nStep 63, monte, prix sortie: 110393.95, solde: 9.78\nStep 64, monte, prix sortie: 110463.36, solde: 9.77\nStep 65, monte, prix sortie: 110754.07, solde: 9.80\nStep 66, monte, prix sortie: 110840.67, solde: 9.83\nStep 67, monte, prix sortie: 110914.52, solde: 9.85\nStep 68, monte, prix sortie: 110993.45, solde: 9.87\nStep 70, baisse, prix sortie: 110486.88, solde: 9.90\nStep 71, baisse, prix sortie: 110631.87, solde: 9.93\nStep 72, baisse, prix sortie: 111445.00, solde: 9.84\nStep 73, baisse, prix sortie: 111574.50, solde: 9.82\nStep 74, baisse, prix sortie: 111911.99, solde: 9.77\nStep 76, monte, prix sortie: 112618.51, solde: 9.84\nStep 77, monte, prix sortie: 112303.87, solde: 9.78\nStep 78, monte, prix sortie: 112256.36, solde: 9.75\nStep 79, monte, prix sortie: 112354.00, solde: 9.75\nStep 80, monte, prix sortie: 113214.78, solde: 9.84\nStep 81, monte, prix sortie: 113084.16, solde: 9.90\nStep 82, monte, prix sortie: 110569.99, solde: 9.67\nStep 83, monte, prix sortie: 110716.82, solde: 9.47\nStep 84, baisse, prix sortie: 110815.40, solde: 9.44\nStep 85, baisse, prix sortie: 110213.99, solde: 9.49\nStep 86, baisse, prix sortie: 111198.78, solde: 9.45\nStep 87, baisse, prix sortie: 111614.54, solde: 9.37\nStep 88, baisse, prix sortie: 111082.22, solde: 9.38\nStep 89, baisse, prix sortie: 111061.73, solde: 9.39\nStep 92, baisse, prix sortie: 110825.60, solde: 9.38\nStep 93, baisse, prix sortie: 110952.76, solde: 9.37\nStep 94, monte, prix sortie: 110695.06, solde: 9.35\nStep 95, monte, prix sortie: 110773.62, solde: 9.34\nStep 96, monte, prix sortie: 110781.02, solde: 9.35\nStep 97, monte, prix sortie: 110832.58, solde: 9.35\nStep 98, monte, prix sortie: 110936.82, solde: 9.36\nStep 99, monte, prix sortie: 110807.77, solde: 9.36\nStep 100, monte, prix sortie: 110384.15, solde: 9.32\nStep 101, baisse, prix sortie: 110671.44, solde: 9.33\nStep 102, baisse, prix sortie: 110103.16, solde: 9.35\nStep 103, baisse, prix sortie: 110228.00, solde: 9.35\nStep 104, baisse, prix sortie: 110038.41, solde: 9.36\nStep 105, baisse, prix sortie: 110044.31, solde: 9.38\nStep 106, baisse, prix sortie: 110201.00, solde: 9.37\nStep 107, baisse, prix sortie: 110170.55, solde: 9.37\nStep 110, monte, prix sortie: 110531.50, solde: 9.39\nStep 111, monte, prix sortie: 110666.24, solde: 9.42\nStep 112, monte, prix sortie: 110629.15, solde: 9.43\nStep 113, monte, prix sortie: 110557.76, solde: 9.42\nStep 114, monte, prix sortie: 110649.44, solde: 9.42\nStep 115, monte, prix sortie: 110504.15, solde: 9.42\nStep 116, monte, prix sortie: 110753.42, solde: 9.43\nStep 117, monte, prix sortie: 110905.58, solde: 9.46\nStep 118, monte, prix sortie: 111115.98, solde: 9.49\nStep 119, monte, prix sortie: 111225.02, solde: 9.50\nStep 120, monte, prix sortie: 111292.13, solde: 9.52\nStep 121, monte, prix sortie: 111115.92, solde: 9.51\nStep 122, monte, prix sortie: 111214.62, solde: 9.50\nStep 123, monte, prix sortie: 111383.05, solde: 9.53\nStep 124, monte, prix sortie: 111053.76, solde: 9.51\nStep 125, monte, prix sortie: 111259.99, solde: 9.54\nStep 126, monte, prix sortie: 111330.30, solde: 9.56\nStep 127, monte, prix sortie: 111050.14, solde: 9.54\nStep 128, monte, prix sortie: 111250.01, solde: 9.54\nStep 129, monte, prix sortie: 111263.87, solde: 9.55\nStep 132, monte, prix sortie: 111093.33, solde: 9.58\nStep 133, monte, prix sortie: 111052.11, solde: 9.59\nStep 134, monte, prix sortie: 110979.35, solde: 9.57\nStep 135, baisse, prix sortie: 111027.16, solde: 9.57\nStep 136, baisse, prix sortie: 111113.26, solde: 9.56\nStep 137, baisse, prix sortie: 111280.39, solde: 9.54\nStep 138, baisse, prix sortie: 112052.43, solde: 9.46\nStep 140, monte, prix sortie: 112272.95, solde: 9.47\nStep 141, monte, prix sortie: 112284.48, solde: 9.50\nStep 142, monte, prix sortie: 112631.75, solde: 9.56\nStep 143, monte, prix sortie: 112398.00, solde: 9.54\nStep 144, monte, prix sortie: 112214.40, solde: 9.50\nStep 145, monte, prix sortie: 112477.01, solde: 9.51\nStep 146, monte, prix sortie: 112097.31, solde: 9.50\nStep 147, monte, prix sortie: 111958.04, solde: 9.45\nStep 148, monte, prix sortie: 112326.45, solde: 9.47\nStep 149, monte, prix sortie: 112236.71, solde: 9.50\nStep 150, monte, prix sortie: 112065.23, solde: 9.47\nStep 151, baisse, prix sortie: 112088.70, solde: 9.49\nStep 152, baisse, prix sortie: 111905.89, solde: 9.50\nStep 153, baisse, prix sortie: 111534.03, solde: 9.51\nStep 155, monte, prix sortie: 112732.62, solde: 9.49\nStep 156, monte, prix sortie: 112433.59, solde: 9.44\nStep 157, monte, prix sortie: 111411.13, solde: 9.33\nStep 158, monte, prix sortie: 111545.88, solde: 9.38\nStep 159, baisse, prix sortie: 111520.43, solde: 9.37\nStep 160, baisse, prix sortie: 111577.31, solde: 9.37\nStep 161, baisse, prix sortie: 111792.33, solde: 9.34\nStep 162, baisse, prix sortie: 112553.65, solde: 9.26\nStep 163, baisse, prix sortie: 112370.08, solde: 9.21\nStep 164, monte, prix sortie: 112274.29, solde: 9.19\nStep 165, monte, prix sortie: 112270.01, solde: 9.18\nStep 166, monte, prix sortie: 112299.99, solde: 9.19\nStep 167, monte, prix sortie: 112615.10, solde: 9.21\nStep 168, monte, prix sortie: 113853.99, solde: 9.21\nStep 169, monte, prix sortie: 113759.89, solde: 9.19\nStep 170, monte, prix sortie: 113738.01, solde: 9.18\nStep 171, monte, prix sortie: 113584.85, solde: 9.17\nStep 172, monte, prix sortie: 113574.52, solde: 9.16\nStep 173, monte, prix sortie: 113566.39, solde: 9.16\nStep 175, baisse, prix sortie: 113881.20, solde: 9.13\nStep 176, baisse, prix sortie: 113960.00, solde: 9.12\nStep 177, baisse, prix sortie: 113885.70, solde: 9.12\nStep 178, baisse, prix sortie: 113903.23, solde: 9.13\nStep 179, monte, prix sortie: 113819.02, solde: 9.12\nStep 180, monte, prix sortie: 114400.01, solde: 9.16\nStep 181, monte, prix sortie: 114158.29, solde: 9.19\nStep 182, monte, prix sortie: 114266.00, solde: 9.18\nStep 183, monte, prix sortie: 114324.64, solde: 9.19\nStep 184, monte, prix sortie: 114083.58, solde: 9.18\nStep 185, monte, prix sortie: 114049.39, solde: 9.15\nStep 186, monte, prix sortie: 113895.29, solde: 9.14\nStep 187, monte, prix sortie: 114062.32, solde: 9.14\nStep 188, monte, prix sortie: 113999.99, solde: 9.15\nStep 189, monte, prix sortie: 113975.99, solde: 9.14\nStep 190, monte, prix sortie: 114628.08, solde: 9.19\nStep 191, monte, prix sortie: 114463.73, solde: 9.23\nStep 192, monte, prix sortie: 114180.31, solde: 9.19\nStep 193, monte, prix sortie: 114487.53, solde: 9.20\nStep 194, monte, prix sortie: 114589.84, solde: 9.23\nStep 195, monte, prix sortie: 114312.35, solde: 9.21\nStep 196, monte, prix sortie: 114419.99, solde: 9.20\nStep 197, monte, prix sortie: 114395.99, solde: 9.21\nStep 198, monte, prix sortie: 114482.69, solde: 9.21\nStep 199, monte, prix sortie: 115084.00, solde: 9.27\nStep 200, monte, prix sortie: 115482.69, solde: 9.35\nStep 201, monte, prix sortie: 115840.69, solde: 9.41\nStep 202, monte, prix sortie: 115377.29, solde: 9.40\nStep 203, monte, prix sortie: 115391.00, solde: 9.37\nStep 204, monte, prix sortie: 115194.14, solde: 9.35\nStep 205, monte, prix sortie: 115359.99, solde: 9.35\nStep 206, monte, prix sortie: 115612.84, solde: 9.38\nStep 207, monte, prix sortie: 115318.00, solde: 9.38\nStep 208, monte, prix sortie: 115086.70, solde: 9.34\nStep 209, monte, prix sortie: 115048.00, solde: 9.31\nStep 210, monte, prix sortie: 115048.01, solde: 9.31\nStep 211, monte, prix sortie: 114980.85, solde: 9.31\nStep 212, monte, prix sortie: 114913.45, solde: 9.29\nStep 213, monte, prix sortie: 115083.97, solde: 9.30\nStep 214, monte, prix sortie: 115166.45, solde: 9.32\nStep 215, monte, prix sortie: 115260.00, solde: 9.34\nStep 216, monte, prix sortie: 115121.18, solde: 9.33\nStep 217, monte, prix sortie: 115495.56, solde: 9.35\nStep 218, monte, prix sortie: 115815.16, solde: 9.41\nStep 219, monte, prix sortie: 116467.32, solde: 9.49\nStep 220, monte, prix sortie: 116632.51, solde: 9.56\nStep 221, monte, prix sortie: 116157.33, solde: 9.53\nStep 222, monte, prix sortie: 115865.89, solde: 9.47\nStep 223, monte, prix sortie: 116027.46, solde: 9.46\nStep 224, monte, prix sortie: 116029.42, solde: 9.47\nStep 225, monte, prix sortie: 116209.32, solde: 9.48\nStep 226, monte, prix sortie: 115764.30, solde: 9.46\nStep 227, monte, prix sortie: 115886.17, solde: 9.44\nStep 228, monte, prix sortie: 115957.00, solde: 9.45\nStep 229, monte, prix sortie: 115698.40, solde: 9.44\nStep 230, monte, prix sortie: 115704.04, solde: 9.42\nStep 231, monte, prix sortie: 115749.99, solde: 9.42\nStep 232, monte, prix sortie: 115778.71, solde: 9.43\nStep 234, baisse, prix sortie: 116035.33, solde: 9.41\nStep 235, baisse, prix sortie: 115937.99, solde: 9.41\nStep 239, baisse, prix sortie: 115850.89, solde: 9.42\nStep 240, baisse, prix sortie: 115768.68, solde: 9.42\nStep 241, baisse, prix sortie: 115402.67, solde: 9.45\nStep 242, baisse, prix sortie: 115235.24, solde: 9.50\nStep 243, baisse, prix sortie: 115871.58, solde: 9.45\nStep 244, baisse, prix sortie: 115918.29, solde: 9.45\nStep 245, monte, prix sortie: 115935.60, solde: 9.45\nStep 246, monte, prix sortie: 115962.93, solde: 9.46\nStep 247, monte, prix sortie: 116093.75, solde: 9.47\nStep 248, monte, prix sortie: 115679.98, solde: 9.45\nStep 249, monte, prix sortie: 115750.99, solde: 9.44\nStep 250, monte, prix sortie: 115858.35, solde: 9.45\nStep 251, monte, prix sortie: 115734.23, solde: 9.45\nStep 252, monte, prix sortie: 115805.39, solde: 9.45\nStep 253, monte, prix sortie: 115969.04, solde: 9.47\nStep 254, monte, prix sortie: 115995.64, solde: 9.48\nStep 255, monte, prix sortie: 116027.26, solde: 9.49\nStep 256, monte, prix sortie: 115794.91, solde: 9.47\nStep 257, monte, prix sortie: 115776.31, solde: 9.45\nStep 258, monte, prix sortie: 115348.10, solde: 9.41\nStep 259, monte, prix sortie: 115401.75, solde: 9.38\nStep 260, monte, prix sortie: 115224.01, solde: 9.37\nStep 261, monte, prix sortie: 115480.00, solde: 9.38\nStep 263, baisse, prix sortie: 115388.21, solde: 9.39\nStep 264, baisse, prix sortie: 115634.99, solde: 9.38\nStep 265, baisse, prix sortie: 115802.16, solde: 9.35\nStep 266, baisse, prix sortie: 116058.88, solde: 9.31\nStep 267, baisse, prix sortie: 116009.61, solde: 9.30\nStep 268, baisse, prix sortie: 115471.68, solde: 9.34\nStep 270, monte, prix sortie: 115231.69, solde: 9.34\nStep 271, monte, prix sortie: 115362.35, solde: 9.36\nStep 272, monte, prix sortie: 115445.45, solde: 9.38\nStep 273, monte, prix sortie: 115764.32, solde: 9.41\nStep 274, monte, prix sortie: 115674.91, solde: 9.43\nStep 276, baisse, prix sortie: 116120.26, solde: 9.46\nStep 277, baisse, prix sortie: 115596.41, solde: 9.51\nStep 279, monte, prix sortie: 114769.04, solde: 9.51\nStep 280, monte, prix sortie: 115070.00, solde: 9.53\nStep 281, monte, prix sortie: 114721.04, solde: 9.52\nStep 282, monte, prix sortie: 114664.08, solde: 9.49\nStep 283, monte, prix sortie: 114983.52, solde: 9.51\nStep 286, monte, prix sortie: 115032.56, solde: 9.53\nStep 287, monte, prix sortie: 114942.28, solde: 9.55\nStep 288, monte, prix sortie: 115532.89, solde: 9.58\nStep 289, monte, prix sortie: 115379.99, solde: 9.59\nStep 290, monte, prix sortie: 115528.00, solde: 9.61\nStep 291, monte, prix sortie: 115529.22, solde: 9.62\nStep 293, monte, prix sortie: 115088.66, solde: 9.60\nStep 294, monte, prix sortie: 115024.24, solde: 9.58\nStep 295, monte, prix sortie: 115034.47, solde: 9.57\nStep 296, monte, prix sortie: 115279.73, solde: 9.59\nStep 297, monte, prix sortie: 115307.26, solde: 9.62\nStep 298, monte, prix sortie: 115602.05, solde: 9.64\nStep 299, monte, prix sortie: 115764.86, solde: 9.66\nStep 300, monte, prix sortie: 115840.00, solde: 9.66\nStep 301, monte, prix sortie: 115658.76, solde: 9.65\nStep 302, monte, prix sortie: 115477.27, solde: 9.62\nStep 303, monte, prix sortie: 115372.46, solde: 9.59\nStep 304, monte, prix sortie: 115287.83, solde: 9.58\nStep 305, monte, prix sortie: 115439.36, solde: 9.58\nStep 306, monte, prix sortie: 115554.54, solde: 9.60\nStep 307, monte, prix sortie: 115296.86, solde: 9.59\nStep 308, monte, prix sortie: 115565.84, solde: 9.62\nStep 309, monte, prix sortie: 115905.25, solde: 9.67\nStep 310, monte, prix sortie: 116242.84, solde: 9.70\nStep 311, monte, prix sortie: 116365.42, solde: 9.73\nStep 312, monte, prix sortie: 116680.29, solde: 9.74\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"del model, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor","metadata":{"id":"SLNIu20NM0t6","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"994453fb-2208-4521-f632-f22d0be0c494"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1302930888.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"execution_count":167},{"cell_type":"markdown","source":"","metadata":{"id":"P7YODgujgJFw"}},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f8sjtHWUabn5","outputId":"28ad899f-69cd-4ead-db87-9fa7333891be"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["254"]},"metadata":{},"execution_count":182}],"execution_count":182},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"id":"xRkVsGrXaf3i"},"outputs":[],"execution_count":183},{"cell_type":"code","source":"print(torch.cuda.memory_allocated() / 1024**2, \"MB\")\nprint(torch.cuda.memory_reserved() / 1024**2, \"MB\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gacnE5lOaiTZ","outputId":"99606fd3-e0f4-43fe-80ae-9d5fc05dd239"},"outputs":[{"output_type":"stream","name":"stdout","text":["551.3447265625 MB\n","584.0 MB\n"]}],"execution_count":184},{"cell_type":"code","source":"","metadata":{"id":"kF0XUOqXalHI"},"outputs":[],"execution_count":null}]}